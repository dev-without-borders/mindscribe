# ğŸ™ï¸ mindscribe GUI - Audio Transcription Tool


[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![GitHub issues](https://img.shields.io/github/issues/dev-without-borders/mindscribe)](https://github.com/dev-without-borders/mindscribe/issues)
[![GitHub stars](https://img.shields.io/github/stars/dev-without-borders/mindscribe)](https://github.com/dev-without-borders/mindscribe/stargazers)

Ein benutzerfreundliches GUI-Tool fÃ¼r hochprÃ¤zise Audio-Transkription mit WhisperX, optimiert fÃ¼r ADHS-freundliche Workflows und Wissensorganisation.
âœ¨ Features

    ğŸ¯ Drag & Drop Support - Dateien einfach ins Fenster ziehen
    ğŸ¬ YouTube Integration - Direkte Transkription von YouTube-Videos
    ğŸ“ Multiple Formate - TXT, SRT, VTT, JSON Export
    ğŸŒ Auto-Spracherkennung - Erkennt Sprache automatisch
    ğŸ”„ Speaker Diarization - Unterscheidet verschiedene Sprecher
    ğŸ§¹ Auto-Cleanup - TemporÃ¤re Dateien werden automatisch gelÃ¶scht
    ğŸ“‚ Quick Access - Ã–ffne Zielordner direkt aus dem Tool

ğŸš€ Installation
1. Voraussetzungen

    Python 3.9 - 3.11 (3.12+ noch nicht vollstÃ¤ndig unterstÃ¼tzt)
    FFmpeg muss installiert sein
    CUDA (optional, fÃ¼r GPU-Beschleunigung)

FFmpeg Installation:

Windows:

# Mit Chocolatey:
choco install ffmpeg

# Oder manuell von: https://ffmpeg.org/download.html
# Und zu PATH hinzufÃ¼gen

Linux:

sudo apt update && sudo apt install ffmpeg

macOS:

brew install ffmpeg

2. Repository klonen / Download

git clone https://github.com/deinusername/whisperx-gui.git
cd whisperx-gui

3. Virtual Environment erstellen

# Virtual Environment erstellen
python -m venv venv

# Aktivieren
# Windows:
venv\Scripts\activate

# Linux/macOS:
source venv/bin/activate

4. Dependencies installieren

pip install -r requirements.txt

FÃ¼r CUDA-UnterstÃ¼tzung (NVIDIA GPU):

# CUDA 11.8 (empfohlen):
pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu118

# CUDA 12.1:
pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu121

ğŸ® Verwendung
Start

python whisperx_gui.py

Workflow

    Source File(s) auswÃ¤hlen:
        ğŸ“ Browse-Button
        ğŸ–±ï¸ Drag & Drop
        ğŸ”— YouTube-URL einfÃ¼gen

    Output Directory festlegen (optional - Standard: ./transcriptions)

    Optionen konfigurieren:
        ğŸŒ Sprache (Auto-Detect empfohlen)
        ğŸ¤ Model (large-v2 fÃ¼r beste QualitÃ¤t)
        ğŸ”„ Speaker Diarization aktivieren
        ğŸ“ Output-Formate wÃ¤hlen

    Transcribe klicken!

    ğŸ“‚ Open Output Folder - Direkter Zugriff auf Ergebnisse

ğŸ“‹ UnterstÃ¼tzte Formate
Input:

    Audio: .mp3, .wav, .m4a, .flac, .ogg, .aac, .wma
    Video: .mp4, .avi, .mkv, .mov, .webm
    Streaming: YouTube-URLs

Output:

    .txt - Einfacher Text
    .srt - Untertitel (mit Timestamps)
    .vtt - WebVTT Untertitel
    .json - VollstÃ¤ndige Metadaten

âš™ï¸ Konfiguration
Models
Model 	QualitÃ¤t 	Geschwindigkeit 	VRAM
tiny 	â­ 	âš¡âš¡âš¡ 	~1 GB
base 	â­â­ 	âš¡âš¡âš¡ 	~1 GB
small 	â­â­â­ 	âš¡âš¡ 	~2 GB
medium 	â­â­â­â­ 	âš¡ 	~5 GB
large-v2 	â­â­â­â­â­ 	âš¡ 	~10 GB

Empfehlung: large-v2 fÃ¼r beste Ergebnisse
Speaker Diarization

BenÃ¶tigt HuggingFace Token:

    Erstelle Account auf huggingface.co
    Gehe zu Settings â†’ Access Tokens
    Erstelle Token und fÃ¼ge es im GUI ein
    Akzeptiere die Bedingungen fÃ¼r:
        pyannote/segmentation
        pyannote/speaker-diarization

ğŸ¯ ADHS-optimierte Features

    Visuelle Fortschrittsanzeige - Immer wissen wo du stehst
    Log-Fenster - Alle Aktionen nachvollziehbar
    Quick-Access - Zielordner sofort Ã¶ffnen
    Auto-Cleanup - Keine temporÃ¤ren Datei-Leichen
    Batch-Processing - Alles auf einmal erledigen
    YouTube-Direct - Kein manuelles Download nÃ¶tig

ğŸ’¡ Workflow-Tipps

FÃ¼r Podcasts/Interviews:

âœ… Speaker Diarization aktivieren
âœ… large-v2 Model
âœ… SRT + TXT Export

FÃ¼r schnelle Notizen:

âœ… Auto-Detect Language
âœ… small/medium Model
âœ… Nur TXT Export

FÃ¼r YouTube-Recherche:

âœ… URL direkt einfÃ¼gen
âœ… Source files lÃ¶schen aktivieren
âœ… Alle Formate exportieren

ğŸ”§ Troubleshooting
"FFmpeg not found"

# Teste ob FFmpeg verfÃ¼gbar ist:
ffmpeg -version

# Falls nicht, installiere es (siehe oben)

"CUDA out of memory"

    Verwende kleineres Model (medium statt large-v2)
    SchlieÃŸe andere GPU-Programme
    Reduziere batch_size im Code

"ModuleNotFoundError: tkinterdnd2"

pip install tkinterdnd2 --force-reinstall

YouTube Download schlÃ¤gt fehl

# Aktualisiere yt-dlp:
pip install -U yt-dlp

Langsame Transkription (CPU)

    Nutze kleineres Model
    Oder installiere CUDA-Support (siehe oben)

ğŸ“¦ PyInstaller Build (Optional)

Erstelle standalone .exe:

# Install PyInstaller
pip install pyinstaller

# Build
pyinstaller --onefile --windowed --name="WhisperX-GUI" whisperx_gui.py

# Executable in: dist/WhisperX-GUI.exe

âš ï¸ Wichtig: FFmpeg muss trotzdem separat installiert sein!
ğŸ¤ Integration mit Obsidian

Perfect fÃ¼r Wissensmanagement:

    Setze Output Directory auf Obsidian Vault
    Nutze TXT-Format
    Erstelle Template fÃ¼r Metadaten:

    ---
    source: {{filename}}
    date: {{date}}
    type: transcription
    ---

    # {{title}}

    {{transcript}}

ğŸ“„ License

MIT License - Siehe LICENSE Datei
ğŸ™ Credits

    WhisperX - Max Bain
    OpenAI Whisper
    yt-dlp

ğŸ’¬ Support

Bei Fragen oder Problemen:

    ğŸ› Issues
    ğŸ’¡ Discussions

Made with â¤ï¸ for better focus and productivity